{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3353,
     "status": "ok",
     "timestamp": 1650701330245,
     "user": {
      "displayName": "Xiaoan Xu",
      "userId": "12248051249160810691"
     },
     "user_tz": -480
    },
    "id": "dQKLTer7yg4b",
    "outputId": "8dc89a50-3b09-447b-ad02-6d060d12fb4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9637376\n",
      "torch.Size([1, 144, 512])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from einops import rearrange, repeat\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, embedding_dim, head_num):\n",
    "        super().__init__()\n",
    "\n",
    "        self.head_num = head_num\n",
    "        self.dk = (embedding_dim // head_num) ** 1 / 2\n",
    "\n",
    "        self.qkv_layer = nn.Linear(embedding_dim, embedding_dim * 3, bias=False)\n",
    "        self.out_attention = nn.Linear(embedding_dim, embedding_dim, bias=False)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        qkv = self.qkv_layer(x)\n",
    "\n",
    "        query, key, value = tuple(rearrange(qkv, 'b t (d k h ) -> k b h t d ', k=3, h=self.head_num))\n",
    "        energy = torch.einsum(\"... i d , ... j d -> ... i j\", query, key) * self.dk\n",
    "\n",
    "        if mask is not None:\n",
    "            energy = energy.masked_fill(mask, -np.inf)\n",
    "\n",
    "        attention = torch.softmax(energy, dim=-1)\n",
    "\n",
    "        x = torch.einsum(\"... i j , ... j d -> ... i d\", attention, value)\n",
    "\n",
    "        x = rearrange(x, \"b h t d -> b t (h d)\")\n",
    "        x = self.out_attention(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, embedding_dim, mlp_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mlp_layers = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, mlp_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(mlp_dim, embedding_dim),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.mlp_layers(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class TransformerEncoderBlock(nn.Module):\n",
    "    def __init__(self, embedding_dim, head_num, mlp_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.multi_head_attention = MultiHeadAttention(embedding_dim, head_num)\n",
    "        self.mlp = MLP(embedding_dim, mlp_dim)\n",
    "\n",
    "        self.layer_norm1 = nn.LayerNorm(embedding_dim)\n",
    "        self.layer_norm2 = nn.LayerNorm(embedding_dim)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        _x = self.multi_head_attention(x)\n",
    "        _x = self.dropout(_x)\n",
    "        x = x + _x\n",
    "        x = self.layer_norm1(x)\n",
    "\n",
    "        _x = self.mlp(x)\n",
    "        x = x + _x\n",
    "        x = self.layer_norm2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, embedding_dim, head_num, mlp_dim, block_num=12):\n",
    "        super().__init__()\n",
    "\n",
    "        self.layer_blocks = nn.ModuleList(\n",
    "            [TransformerEncoderBlock(embedding_dim, head_num, mlp_dim) for _ in range(block_num)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer_block in self.layer_blocks:\n",
    "            x = layer_block(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class ViT(nn.Module):\n",
    "    def __init__(self, img_dim, in_channels, embedding_dim, head_num, mlp_dim,\n",
    "                 block_num, patch_dim, classification=False, num_classes=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.patch_dim = patch_dim\n",
    "        self.classification = classification\n",
    "        self.num_tokens = (img_dim // patch_dim) ** 2\n",
    "        self.token_dim = in_channels * (patch_dim ** 2)\n",
    "\n",
    "        self.projection = nn.Linear(self.token_dim, embedding_dim)\n",
    "        self.embedding = nn.Parameter(torch.rand(self.num_tokens + 1, embedding_dim))\n",
    "\n",
    "        self.cls_token = nn.Parameter(torch.randn(1, 1, embedding_dim))\n",
    "\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "        self.transformer = TransformerEncoder(embedding_dim, head_num, mlp_dim, block_num)\n",
    "\n",
    "        if self.classification:\n",
    "            self.mlp_head = nn.Linear(embedding_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        img_patches = rearrange(x,\n",
    "                                'b c (patch_x x) (patch_y y) -> b (x y) (patch_x patch_y c)',\n",
    "                                patch_x=self.patch_dim, patch_y=self.patch_dim)\n",
    "\n",
    "        batch_size, tokens, _ = img_patches.shape\n",
    "\n",
    "        project = self.projection(img_patches)\n",
    "        token = repeat(self.cls_token, 'b ... -> (b batch_size) ...',\n",
    "                       batch_size=batch_size)\n",
    "\n",
    "        patches = torch.cat([token, project], dim=1)\n",
    "        patches += self.embedding[:tokens + 1, :]\n",
    "\n",
    "        x = self.dropout(patches)\n",
    "        x = self.transformer(x)\n",
    "        x = self.mlp_head(x[:, 0, :]) if self.classification else x[:, 1:, :]\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    vit = ViT(img_dim=48,\n",
    "              in_channels=13,\n",
    "              patch_dim=4,\n",
    "              embedding_dim=512,\n",
    "              block_num=6,\n",
    "              head_num=4,\n",
    "              mlp_dim=512)\n",
    "    print(sum(p.numel() for p in vit.parameters()))\n",
    "    print(vit(torch.rand(1, 13, 48, 48)).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 986,
     "status": "ok",
     "timestamp": 1650701333281,
     "user": {
      "displayName": "Xiaoan Xu",
      "userId": "12248051249160810691"
     },
     "user_tz": -480
    },
    "id": "vMOlmhGcycj6",
    "outputId": "16873ee9-4015-4292-ac9e-de426f31f79c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15478368\n",
      "torch.Size([1, 16, 48, 48])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from einops import rearrange\n",
    "class ACBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ACBlock, self).__init__()\n",
    "        self.squre = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=1)\n",
    "        self.cross_ver = nn.Conv2d(in_channels, out_channels, kernel_size=(1, 3), padding=(0, 1), stride=1)\n",
    "        self.cross_hor = nn.Conv2d(in_channels, out_channels, kernel_size=(3, 1), padding=(1, 0), stride=1)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.ReLU = nn.ReLU(True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.squre(x)\n",
    "        x2 = self.cross_ver(x)\n",
    "        x3 = self.cross_hor(x)\n",
    "        return self.ReLU(self.bn(x1 + x2 + x3))\n",
    "\n",
    "class EncoderBottleneck(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, base_width=64):\n",
    "        super().__init__()\n",
    "\n",
    "        self.downsample = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "\n",
    "        width = int(out_channels * (base_width / 64))\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, width, kernel_size=1, stride=1, bias=False)\n",
    "        self.norm1 = nn.BatchNorm2d(width)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(width, width, kernel_size=3, stride=2, groups=1, padding=1, dilation=1, bias=False)\n",
    "        self.norm2 = nn.BatchNorm2d(width)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(width, out_channels, kernel_size=1, stride=1, bias=False)\n",
    "        self.norm3 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_down = self.downsample(x)\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.norm1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.norm2(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.norm3(x)\n",
    "        x = x + x_down\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class DecoderBottleneck(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, scale_factor=2):\n",
    "        super().__init__()\n",
    "\n",
    "        self.upsample = nn.Upsample(scale_factor=scale_factor, mode='bilinear', align_corners=True)\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, x_concat=None):\n",
    "        x = self.upsample(x)\n",
    "        \n",
    "        if x_concat is not None:\n",
    "            x = torch.cat([x_concat, x], dim=1)\n",
    "        x = self.layer(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, img_dim, in_channels, out_channels, head_num, mlp_dim, block_num, patch_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1, bias=False) # 7 3\n",
    "        self.norm1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.encoder1 = EncoderBottleneck(out_channels, out_channels * 2, stride=2)\n",
    "        self.encoder2 = EncoderBottleneck(out_channels * 2, out_channels * 4, stride=2)\n",
    "        \n",
    "\n",
    "        self.vit_img_dim = img_dim // patch_dim\n",
    "        self.vit = ViT(self.vit_img_dim, out_channels * 4, out_channels * 4,\n",
    "                       head_num, mlp_dim, block_num, patch_dim=1, classification=False)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_channels * 4, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.norm2 = nn.BatchNorm2d(256) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.norm1(x)\n",
    "        x1 = self.relu(x)\n",
    "\n",
    "        x2 = self.encoder1(x1)\n",
    "        x = self.encoder2(x2)\n",
    "        \n",
    "        x = self.vit(x)\n",
    "        x = rearrange(x, \"b (x y) c -> b c x y\", x=self.vit_img_dim, y=self.vit_img_dim)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.norm2(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x, x1, x2 \n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, out_channels, class_num):\n",
    "        super().__init__()\n",
    "\n",
    "        self.decoder2 = DecoderBottleneck(out_channels * 4, out_channels)\n",
    "        self.decoder3 = DecoderBottleneck(out_channels * 2, int(out_channels * 1 / 2))\n",
    "        self.decoder4 = DecoderBottleneck(int(out_channels * 1 / 2), int(out_channels * 1 / 8))\n",
    "\n",
    "\n",
    "    def forward(self, x, x1, x2):\n",
    "        x = self.decoder2(x, x2)\n",
    "        x = self.decoder3(x, x1)\n",
    "        x = self.decoder4(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class TransUNet(nn.Module):\n",
    "    def __init__(self, img_dim, in_channels, out_channels, head_num, mlp_dim, block_num, patch_dim, class_num):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = Encoder(img_dim, in_channels, out_channels,\n",
    "                               head_num, mlp_dim, block_num, patch_dim)\n",
    "\n",
    "        self.decoder = Decoder(out_channels, class_num)\n",
    "        #self.block1 = ACBlock(out_channels,out_channels)\n",
    "        #self.block2 = ACBlock(2*out_channels,2*out_channels)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x, x1, x2 = self.encoder(x) \n",
    "        #x1 = self.block1(x1)\n",
    "        #x2 = self.block2(x2)\n",
    "        x = self.decoder(x, x1, x2) \n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import torch\n",
    "\n",
    "    transunet = TransUNet(img_dim=48,\n",
    "                          in_channels=13,\n",
    "                          out_channels=128,\n",
    "                          head_num=4,\n",
    "                          mlp_dim=512,\n",
    "                          block_num=6,\n",
    "                          patch_dim=8,\n",
    "                          class_num=18)\n",
    "\n",
    "    print(sum(p.numel() for p in transunet.parameters()))\n",
    "    print(transunet(torch.randn(1, 13, 48, 48)).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 599,
     "status": "ok",
     "timestamp": 1650701344551,
     "user": {
      "displayName": "Xiaoan Xu",
      "userId": "12248051249160810691"
     },
     "user_tz": -480
    },
    "id": "zXl3Tgnv4SuL",
    "outputId": "e0daa24d-47fa-4188-e0c2-2c550fbed23e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not find visdom package. try 'pip install visdom'. continue without...\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"/content/drive/MyDrive/Colabdocument/MTLCC-pytorch-master/src\")\n",
    "\n",
    "import torch\n",
    "from utils.dataset import ijgiDataset as Dataset\n",
    "from utils.snapshot import resume\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M60QSXBRVVrR"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def attn(query, key, value):\n",
    "    scores = query.transpose(1, 2) @ key / math.sqrt(query.size(1))  # (N, S, S)\n",
    "    attn = F.softmax(scores, dim=-1)\n",
    "    output = attn @ value.transpose(1, 2)\n",
    "    return output.transpose(1, 2)  # (N, C, S)\n",
    "\n",
    "\n",
    "class SAAttnMem(nn.Module):\n",
    "    def __init__(self, input_dim, d_model, kernel_size):\n",
    "        super().__init__()\n",
    "        pad = kernel_size[0] // 2, kernel_size[1] // 2\n",
    "        self.d_model = d_model\n",
    "        self.input_dim = input_dim\n",
    "        self.conv_h = nn.Conv2d(input_dim, d_model*3, kernel_size=1)\n",
    "        self.conv_m = nn.Conv2d(input_dim, d_model*2, kernel_size=1)\n",
    "        self.conv_z = nn.Conv2d(d_model*2, d_model, kernel_size=1)\n",
    "        self.conv_output = nn.Conv2d(input_dim+d_model, input_dim*3, kernel_size=kernel_size, padding=pad)\n",
    "\n",
    "    def forward(self, h, m):\n",
    "        hq, hk, hv = torch.split(self.conv_h(h), self.d_model, dim=1)\n",
    "        mk, mv = torch.split(self.conv_m(m), self.d_model, dim=1)\n",
    "        N, C, H, W = hq.size()\n",
    "        Zh = attn(hq.view(N, C, -1), hk.view(N, C, -1), hv.view(N, C, -1))  \n",
    "        Zm = attn(hq.view(N, C, -1), mk.view(N, C, -1), mv.view(N, C, -1))  \n",
    "        Z = self.conv_z(torch.cat([Zh.view(N, C, H, W), Zm.view(N, C, H, W)], dim=1))\n",
    "        i, g, o = torch.split(self.conv_output(torch.cat([Z, h], dim=1)), self.input_dim, dim=1)\n",
    "        i = torch.sigmoid(i)\n",
    "        g = torch.tanh(g)\n",
    "        m_next = i * g + (1 - i) * m\n",
    "        h_next = torch.sigmoid(o) * m_next\n",
    "        return h_next, m_next\n",
    "\n",
    "\n",
    "class SAConvLSTMCell(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, d_attn, kernel_size):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        pad = kernel_size[0] // 2, kernel_size[1] // 2\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels=input_dim + hidden_dim,\n",
    "                              out_channels=4 * hidden_dim,\n",
    "                              kernel_size=kernel_size,\n",
    "                              padding=pad)\n",
    "        self.sa = SAAttnMem(input_dim=hidden_dim, d_model=d_attn, kernel_size=kernel_size)\n",
    "\n",
    "    def forward(self, inputs, cell_state, hidden_state, memory_state):\n",
    "\n",
    "        combined = torch.cat([inputs, hidden_state], dim=1)\n",
    "\n",
    "        combined_conv = self.conv(combined)\n",
    "        cc_i, cc_f, cc_o, cc_g = torch.split(combined_conv, self.hidden_dim, dim=1)\n",
    "        i = torch.sigmoid(cc_i)\n",
    "        f = torch.sigmoid(cc_f)\n",
    "        o = torch.sigmoid(cc_o)\n",
    "        g = torch.tanh(cc_g)\n",
    "\n",
    "        cell_state = f * cell_state + i * g\n",
    "        hidden_state = o * torch.tanh(cell_state)\n",
    "        hidden_state, memory_state = self.sa(hidden_state, memory_state)\n",
    "        return cell_state,hidden_state,memory_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KODOABisUuS4"
   },
   "outputs": [],
   "source": [
    "class LSTMSequentialEncoder(torch.nn.Module):\n",
    "    def __init__(self, height, width, input_dim=13, hidden_dim=64, nclasses=8, kernel_size=(3,3), bias=False):\n",
    "        super(LSTMSequentialEncoder, self).__init__()\n",
    "\n",
    "        self.inconv = torch.nn.Conv3d(input_dim,hidden_dim,(1,3,3))\n",
    "        self.cell = SAConvLSTMCell(input_dim,input_dim,input_dim,kernel_size)\n",
    "        self.final = torch.nn.Conv2d(input_dim, nclasses, (1, 1))\n",
    "\n",
    "    def forward(self, x1, hidden=None, state=None):\n",
    "\n",
    "        # (b x t x c x h x w) -> (b x c x t x h x w)\n",
    "        x1 = x1.permute(0,2,1,3,4)\n",
    "\n",
    "        b, c, t, h, w = x1.shape\n",
    "\n",
    "        hidden1 = torch.zeros(b, c, h, w).cuda()\n",
    "        cell1 = torch.zeros(b, c, h, w).cuda()\n",
    "        memory1 = torch.zeros(b, c, h, w).cuda()\n",
    "        \n",
    "\n",
    "        for iter in range(t):\n",
    "            cell1,hidden1,memory1 = self.cell.forward(x1[:,:,iter,:,:], cell1,hidden1,memory1)\n",
    "\n",
    "\n",
    "        x = self.final.forward(cell1)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GP1mn3xd245R"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self,img_dim=48,in_channels=3,out_channels=64,head_num=4,mlp_dim=512,block_num=6,patch_dim=16,class_num=18,height=48, width=48, input_dim=18, hidden_dim=64, nclasses=8, kernel_size=(3,3), bias=False):\n",
    "        super(Model,self).__init__()\n",
    "        self.transunet = TransUNet(img_dim=48,\n",
    "                          in_channels=13,\n",
    "                          out_channels=128,\n",
    "                          head_num=4,\n",
    "                          mlp_dim=512,\n",
    "                          block_num=6,\n",
    "                          patch_dim=8,\n",
    "                          class_num=18)\n",
    "        \n",
    "        self.lstm = LSTMSequentialEncoder(48,48,input_dim=16,nclasses=18)\n",
    "        self.lstm = torch.nn.DataParallel(self.lstm).cuda()\n",
    "    \n",
    "    def forward(self,input,target):\n",
    "        list = []\n",
    "        for i in range(30):\n",
    "            list.append(self.transunet(input[:,i,:,:,:]).unsqueeze(1))\n",
    "        input1 = torch.cat(list,dim=1)\n",
    "        input1 = input1.cuda()\n",
    "        target = target.cuda()\n",
    "        \n",
    "        return self.lstm(input1),target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 574
    },
    "executionInfo": {
     "elapsed": 33148,
     "status": "error",
     "timestamp": 1650701389377,
     "user": {
      "displayName": "Xiaoan Xu",
      "userId": "12248051249160810691"
     },
     "user_tz": -480
    },
    "id": "kXruYKqbqFJA",
    "outputId": "c1a5e7e0-6842-4d43-fc87-a9f040eacaa7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================] 6534/6534 (100%)    0 to go\n",
      "[=======                                 ]  394/2016 ( 19%) 1622 to go"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rejected_nopath:2562, rejected_length:100, total_samples:3872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[========================================] 2016/2016 (100%)    0 to go\n",
      "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  cpuset_checked))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rejected_nopath:784, rejected_length:19, total_samples:1213\n",
      "\n",
      "Epoch 0\n",
      "train\n",
      "iteration: 7/968, logs/sec: 4.72, loss: 2.93"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-1f7a787fc6b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0msnapshot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m         \u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/TransUNet+SAConvLSTM'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     )\n",
      "\u001b[0;32m<ipython-input-9-1f7a787fc6b9>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(datadir, batchsize, workers, epochs, lr, snapshot, checkpoint_dir)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraindataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\ntest\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-1f7a787fc6b9>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(dataloader, network, optimizer, loss, logger)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mbatch_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m             \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-cc13c9a4b656>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mlist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransunet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0minput1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0minput1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-26f1c052de37>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m         \u001b[0;31m#x1 = self.block1(x1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;31m#x2 = self.block2(x2)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-26f1c052de37>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrearrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"b (x y) c -> b c x y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvit_img_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvit_img_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-788ef385d98d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp_head\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-788ef385d98d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer_block\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer_blocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-788ef385d98d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0m_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_head_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0m_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0m_x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-788ef385d98d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrearrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"b h t d -> b t (h d)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch.nn\n",
    "from utils.dataset import ijgiDataset as Dataset\n",
    "from utils.logger import Logger, Printer\n",
    "import argparse\n",
    "from utils.snapshot import save, resume\n",
    "import os\n",
    "\n",
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"data\", type=str,help=\"path to dataset\")\n",
    "    parser.add_argument('-b', \"--batchsize\", default=1 , type=int, help=\"batch size\")\n",
    "    parser.add_argument('-w', \"--workers\", default=0, type=int, help=\"number of dataset worker threads\")\n",
    "    parser.add_argument('-e', \"--epochs\", default=10, type=int, help=\"epochs to train\")\n",
    "    parser.add_argument('-l', \"--learning_rate\", default=1e-3, type=float, help=\"learning rate\")\n",
    "    parser.add_argument('-s', \"--snapshot\", default=None, type=str, help=\"load weights from snapshot\")\n",
    "    parser.add_argument('-c', \"--checkpoint_dir\", default=None, type=str, help=\"directory to save checkpoints\")\n",
    "    return parser.parse_args()\n",
    "\n",
    "def main(\n",
    "    datadir,\n",
    "    batchsize = 16,\n",
    "    workers = 0,\n",
    "    epochs = 10,\n",
    "    lr = 1e-3,\n",
    "    snapshot = None,\n",
    "    checkpoint_dir = None\n",
    "    ):\n",
    "\n",
    "    traindataset = Dataset(datadir, tileids=\"tileids/train_fold0.tileids\")\n",
    "    testdataset = Dataset(datadir, tileids=\"tileids/test_fold0.tileids\")\n",
    "\n",
    "    nclasses = len(traindataset.classes)\n",
    "\n",
    "    traindataloader = torch.utils.data.DataLoader(traindataset,batch_size=batchsize,shuffle=True,num_workers=workers)\n",
    "    testdataloader = torch.utils.data.DataLoader(testdataset,batch_size=batchsize,shuffle=False,num_workers=workers)\n",
    "\n",
    "    logger = Logger(columns=[\"loss\"], modes=[\"train\", \"test\"])\n",
    "\n",
    "\n",
    "    network = Model()\n",
    "\n",
    "    optimizer = torch.optim.Adam(network.parameters(), lr=lr,weight_decay=1e-3)\n",
    "    loss = torch.nn.NLLLoss()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        network = torch.nn.DataParallel(network).cuda()\n",
    "        loss = loss.cuda()\n",
    "\n",
    "    start_epoch = 0\n",
    "\n",
    "    if snapshot is not None:\n",
    "        state = resume(snapshot,model=network, optimizer=optimizer)\n",
    "\n",
    "        if \"epoch\" in state.keys():\n",
    "            start_epoch = state[\"epoch\"] + 1\n",
    "\n",
    "        if \"data\" in state.keys():\n",
    "            logger.resume(state[\"data\"])\n",
    "\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "\n",
    "        logger.update_epoch(epoch)\n",
    "\n",
    "        print(\"\\nEpoch {}\".format(epoch))\n",
    "        print(\"train\")\n",
    "        \n",
    "        train_epoch(traindataloader, network, optimizer, loss, logger)\n",
    "        print(\"\\ntest\")\n",
    "        \n",
    "        test_epoch(testdataloader, network,loss, logger)\n",
    "\n",
    "        data = logger.get_data()\n",
    "\n",
    "\n",
    "        if checkpoint_dir is not None:\n",
    "            checkpoint_name = os.path.join(checkpoint_dir,\"model_{:02d}.pth\".format(epoch))\n",
    "            save(checkpoint_name, network, optimizer, epoch=epoch, data=data)\n",
    "        logger.save_csv('/content/TransUNet+SAConvLSTM/epoch_data.csv')\n",
    "\n",
    "def train_epoch(dataloader, network, optimizer, loss, logger):\n",
    "    network.train()\n",
    "    printer = Printer(N=len(dataloader))\n",
    "    logger.set_mode(\"train\")\n",
    "\n",
    "    for iteration, data in enumerate(dataloader):\n",
    "        if iteration%4 == 0:\n",
    "            optimizer.zero_grad()\n",
    "            batch_loss = 0\n",
    "        \n",
    "        input, target = data \n",
    "        output,target = network.forward(input,target)\n",
    "        l = loss(output, target)\n",
    "        batch_loss += l/4\n",
    "        l.backward()\n",
    "\n",
    "        if (iteration+1)%4 == 0:\n",
    "            stats = {\"loss\":batch_loss.data.cpu().numpy()}\n",
    "            optimizer.step()\n",
    "            \n",
    "            \n",
    "            printer.print(stats, iteration)\n",
    "            logger.log(stats, (iteration+1)/4)\n",
    "\n",
    "def test_epoch(dataloader, network, loss, logger):\n",
    "    network.eval()\n",
    "    printer = Printer(N=len(dataloader))\n",
    "    logger.set_mode(\"test\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for iteration, data in enumerate(dataloader):\n",
    "            if iteration%4 == 0:\n",
    "                batch_loss = 0\n",
    "\n",
    "            input, target = data\n",
    "            \n",
    "            output,target = network.forward(input,target)\n",
    "            l = loss(output, target)\n",
    "            batch_loss += l/4\n",
    "\n",
    "            if (iteration+1)%4 == 0:\n",
    "                stats = {\"loss\":batch_loss.data.cpu().numpy()}\n",
    "\n",
    "                printer.print(stats, iteration)\n",
    "                logger.log(stats, (iteration+1)/4)\n",
    "            \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "\n",
    "    main(\n",
    "        'data',\n",
    "        batchsize=4,\n",
    "        workers=8,\n",
    "        epochs=100,\n",
    "        lr=1e-3,\n",
    "        snapshot=None,\n",
    "        checkpoint_dir='/content/TransUNet+SAConvLSTM'\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOsCT6WqAlJ2D5pjoroJdR/",
   "collapsed_sections": [],
   "mount_file_id": "13_ID-NB7hmh8GUOk1jLSKL06jfq7i-Kf",
   "name": "Trans-ConvLSTM",
   "provenance": [
    {
     "file_id": "13_ID-NB7hmh8GUOk1jLSKL06jfq7i-Kf",
     "timestamp": 1650701395349
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
